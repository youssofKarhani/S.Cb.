{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34vBQTIHe201"
      },
      "source": [
        "## Imports and Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: tensorflw\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip show tensorflw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fieYrfGzdxGV",
        "outputId": "b073635d-6296-46ad-b1e9-be5d8d3b3429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp310-cp310-macosx_10_9_x86_64.whl (197 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.6/197.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py in /Users/y.k./Desktop/uni/CSIS290-BS_Project/Project/Test3_GPT/venv/lib/python3.10/site-packages (3.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /Users/y.k./Desktop/uni/CSIS290-BS_Project/Project/Test3_GPT/venv/lib/python3.10/site-packages (from h5py) (1.23.4)\n",
            "Installing collected packages: pyyaml\n",
            "Successfully installed pyyaml-6.0\n",
            "2.11.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/y.k./nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#! pip3 install keras\n",
        "#! pip3 install tensorflow\n",
        "#! pip3 install Keras-Preprocessing\n",
        "#! pip3 install nltk\n",
        "# ! pip3 install pyyaml h5py\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,Bidirectional,LSTM,GRU,Dense\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "nltk.download('punkt')\n",
        "warnings.filterwarnings('ignore')\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INtk8pTAe1GH"
      },
      "source": [
        "## Connecting to dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmBjCdbOfNSo",
        "outputId": "34b0d63a-4728-4859-d34d-0eec6cd9f318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /Users/y.k./Desktop/Downloads/Datasets_S_Cb/archive.zip\n",
            "replace test.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ]
        }
      ],
      "source": [
        "!unzip \"/Users/y.k./Desktop/Downloads/Datasets_S_Cb/archive.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jxb64CC3gakq"
      },
      "outputs": [],
      "source": [
        "f=open('train.txt','r')\n",
        "x_train=[]\n",
        "y_train=[]\n",
        "for i in f:\n",
        "    l=i.split(';')\n",
        "    y_train.append(l[1].strip())\n",
        "    x_train.append(l[0])\n",
        "f=open('test.txt','r')\n",
        "x_test=[]\n",
        "y_test=[]\n",
        "for i in f:\n",
        "    l=i.split(';')\n",
        "    y_test.append(l[1].strip())\n",
        "    x_test.append(l[0])\n",
        "f=open('val.txt','r')\n",
        "for i in f:\n",
        "    l=i.split(';')\n",
        "    y_test.append(l[1].strip())\n",
        "    x_test.append(l[0])\n",
        "data_train=pd.DataFrame({'Text':x_train,'Emotion':y_train})\n",
        "data_test=pd.DataFrame({'Text':x_test,'Emotion':y_test})\n",
        "data=data_train.append(data_test,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eiztEvsRgil7"
      },
      "outputs": [],
      "source": [
        "def clean_text(data):\n",
        "    data=re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\n",
        "    data=re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\n",
        "    data=word_tokenize(data)\n",
        "    return data\n",
        "texts=[' '.join(clean_text(text)) for text in data.Text]\n",
        "texts_train=[' '.join(clean_text(text)) for text in x_train]\n",
        "texts_test=[' '.join(clean_text(text)) for text in x_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "04diEudXglsM"
      },
      "outputs": [],
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequence_train=tokenizer.texts_to_sequences(texts_train)\n",
        "sequence_test=tokenizer.texts_to_sequences(texts_test)\n",
        "index_of_words=tokenizer.word_index\n",
        "vocab_size=len(index_of_words)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tklkb0h_gpMT"
      },
      "outputs": [],
      "source": [
        "num_classes=6\n",
        "embed_num_dims=300\n",
        "max_seq_len=500\n",
        "class_names=['anger','sadness','fear','joy','surprise','love']\n",
        "X_train_pad=pad_sequences(sequence_train,maxlen=max_seq_len)\n",
        "X_test_pad=pad_sequences(sequence_test,maxlen=max_seq_len)\n",
        "encoding={'anger':0,'sadness':1,'fear':2,'joy':3,'surprise':4,'love':5}\n",
        "y_train=[encoding[x] for x in data_train.Emotion]\n",
        "y_test=[encoding[x] for x in data_test.Emotion]\n",
        "y_train=to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_HWb23Kha3s",
        "outputId": "e3f105dc-7a99-41ac-db65-d96c5c28295e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /Users/y.k./Desktop/Downloads/Datasets_S_Cb/wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/Users/y.k./Desktop/Downloads/Datasets_S_Cb/wiki-news-300d-1M.vec.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZfbnySzTgr0h"
      },
      "outputs": [],
      "source": [
        "def create_embedding_matrix(filepath,word_index,embedding_dim):\n",
        "    vocab_size=len(word_index)+1\n",
        "    embedding_matrix=np.zeros((vocab_size,embedding_dim))\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word,*vector=line.split()\n",
        "            if word in word_index:\n",
        "                idx=word_index[word]\n",
        "                embedding_matrix[idx] = np.array(vector,dtype=np.float32)[:embedding_dim]\n",
        "    return embedding_matrix\n",
        "fname='wiki-news-300d-1M.vec'\n",
        "embedd_matrix=create_embedding_matrix(fname,index_of_words,embed_num_dims)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "FqiaMmIygtzh",
        "outputId": "f506faac-15bd-4526-af9f-066b9544fa23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-28 00:56:18.811945: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "embedd_layer=Embedding(vocab_size,embed_num_dims,input_length=max_seq_len,weights=[embedd_matrix],trainable=False)\n",
        "gru_output_size=128\n",
        "bidirectional=True\n",
        "model=Sequential()\n",
        "model.add(embedd_layer)\n",
        "model.add(Bidirectional(GRU(units=gru_output_size,dropout=0.2,recurrent_dropout=0.2)))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AK4IgEx0cNz",
        "outputId": "dc445cdd-db13-473b-c0da-d633443a73d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "125/125 [==============================] - 361s 3s/step - loss: 1.3809 - accuracy: 0.4835 - val_loss: 1.1150 - val_accuracy: 0.6100\n",
            "Epoch 2/8\n",
            "125/125 [==============================] - 376s 3s/step - loss: 0.8637 - accuracy: 0.7038 - val_loss: 0.6224 - val_accuracy: 0.7870\n",
            "Epoch 3/8\n",
            "125/125 [==============================] - 387s 3s/step - loss: 0.5190 - accuracy: 0.8217 - val_loss: 0.3696 - val_accuracy: 0.8748\n",
            "Epoch 4/8\n",
            "125/125 [==============================] - 354s 3s/step - loss: 0.3394 - accuracy: 0.8812 - val_loss: 0.2704 - val_accuracy: 0.9003\n",
            "Epoch 5/8\n",
            "125/125 [==============================] - 357s 3s/step - loss: 0.2555 - accuracy: 0.9078 - val_loss: 0.2236 - val_accuracy: 0.9162\n",
            "Epoch 6/8\n",
            "125/125 [==============================] - 375s 3s/step - loss: 0.2224 - accuracy: 0.9156 - val_loss: 0.2045 - val_accuracy: 0.9218\n",
            "Epoch 7/8\n",
            "125/125 [==============================] - 373s 3s/step - loss: 0.1922 - accuracy: 0.9249 - val_loss: 0.1772 - val_accuracy: 0.9283\n",
            "Epoch 8/8\n",
            "125/125 [==============================] - 337s 3s/step - loss: 0.1796 - accuracy: 0.9262 - val_loss: 0.1572 - val_accuracy: 0.9287\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x133b52e30>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size=128\n",
        "epochs=8\n",
        "model.fit(X_train_pad,y_train,batch_size=batch_size,epochs=epochs,validation_data=(X_test_pad,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4J0bz8b0geP",
        "outputId": "7be42d16-2195-4f29-a74f-d006d42b38a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Message:['I am sad.']\n",
            "Emotion: sadness\n"
          ]
        }
      ],
      "source": [
        "message=['I am sad.']\n",
        "seq=tokenizer.texts_to_sequences(message)\n",
        "padded=pad_sequences(seq,maxlen=max_seq_len)\n",
        "pred=model.predict(padded)\n",
        "print('Message:'+str(message))\n",
        "print('Emotion:',class_names[np.argmax(pred)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "mWZmmdvA2sQ_",
        "outputId": "9e787400-0af2-443f-9d77-be9d91acecd1"
      },
      "outputs": [],
      "source": [
        "model.save('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WwESis422ufI"
      },
      "outputs": [],
      "source": [
        "New_Model = tf.keras.models.load_model('my_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 136ms/step\n",
            "Message:['I am sad.']\n",
            "Emotion: sadness\n"
          ]
        }
      ],
      "source": [
        "message=['I am sad.']\n",
        "seq=tokenizer.texts_to_sequences(message)\n",
        "padded=pad_sequences(seq,maxlen=max_seq_len)\n",
        "pred=New_Model.predict(padded)\n",
        "print('Message:'+str(message))\n",
        "print('Emotion:',class_names[np.argmax(pred)])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7 (default, Sep  3 2021, 12:37:55) \n[Clang 12.0.5 (clang-1205.0.22.9)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
